{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cacb885a",
   "metadata": {},
   "source": [
    "# Tarea 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5574997",
   "metadata": {},
   "source": [
    "### NOMBRE ESTUDIANTE: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadd9d06",
   "metadata": {},
   "source": [
    "### CODIGO ESTUDIANTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f0c7e3",
   "metadata": {},
   "source": [
    "Use este mismo Jupyter Notebook pero cambiele de nombre a que sea:\n",
    "\n",
    "Tarea2_ML_Nombre_Apellido.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473fde84",
   "metadata": {},
   "source": [
    "Bueno el proposito de esta tarea de enfrentarlos a un problema \"real\" en donde aplicaran varios de los modelos que discutimos en los notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41321be4",
   "metadata": {},
   "source": [
    "# lo primero que haremos es encontrar/buscar/cargar los datos\n",
    "\n",
    "Ahora para esta tarea haremos uso de una base de datos que guarda texto. Cualquier persona que hay sido abusada o que haya sido amenazada \"online\" sabe perfectamente que este tipo de cosas no se va cuando tu apagas el telefono o cuando apagas la computadora. En esta tare vamos a trabajar en un modelo multi clase que detecta varios tipos de toxicidad desde toxico severo, amenazas, obsenidad, insultos, etc. Antes de comenzar, si usted es sensible a estas palabras, por favor no continue y hable conmigo, mi plan no es ofenderlo, ni que se sienta mal pero darle un problema que tiene un interes muy grande en la comunidad.\n",
    "\n",
    "En esta tarea usaremos clasificadores supervisados y representacion de textos. Un comentario toxico puede ser considerado, toxico, severamente toxico, obceno, amenazante, insultante o que tenga identidad de odio, todo al mismo tiempo o ninguno de ellos.\n",
    "\n",
    "Los datos los vamos a sacar de este link\n",
    "\n",
    "https://www.kaggle.com/code/jhoward/nb-svm-strong-linear-baseline/data\n",
    "\n",
    "Este archivo se puede bajar en formato csv. Hagalo y si esta usando google collab, entonces pasa el archivo a su google drive. Lo mas seguro es que tengas que abrir una cuenta en este sitio, lo cual no cuesta nada pero para poder bajar los datos. Por supuesto, parte de esta tarea es buscar como bajar los datos. Al final vas a poder hacerlo :-). El mas importante, que usaran para la tarea se llama train.csv.\n",
    "\n",
    "De ahora en adelante asumo que los datos estan ya disponible para ser leido por este Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22209c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a importar todas las librerias necesarias\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# de esta libreria no hemos hablado, pero es una libreria en Python para manipular texto\n",
    "# hay varios links que les puede servir para entenderlo, yo les recomiendo\n",
    "#\n",
    "# https://www.mygreatlearning.com/blog/regular-expression-in-python/\n",
    "# https://towardsdatascience.com/regex-with-python-b4c5ca7c1eba\n",
    "#\n",
    "import re\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# la siguiente hace lo siguiente\n",
    "# convierte documentos (o textos) a una matrix  TF-IDF\n",
    "# este concepto de TF-IDF significa en ingles Term Frequenct Inverse Document Frequency\n",
    "# que es una manera de medir que tan importante es una palabra en el contexto del documento\n",
    "# EL TF = (Nuvemo de veces que el termino t aparece en el documento) / (Numero total de terminos en el documento)\n",
    "# IDF = log10(Numero total de documentos/ Numero total de documentos con el termino t en el).\n",
    "# TF-IDF = TF*IDF\n",
    "#\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#este es un clasificador my paredico al que hablamos en clase\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# El proceso de convertir datos a algo que el computador pueda entender se llama preprocesamiento.\n",
    "# Uno de las etapas mas importante es la de filtrar datos que no tienen ninguna utilidad\n",
    "# En procesamiento de lenguaje (Natural Language Processing) estas se llaman \"stop words\"\n",
    "# es decir eliminar del analisis palabras como \"the\" \"a\", etc.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c49c90cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ok ahora ya tienes todos los paquetes y ademas tienes el archivo de datos en disco\n",
    "# Importe el archivo train.csv, cuando lo lean y para evitar problemas de caracteres extra√±os\n",
    "# use encoding = \"ISO-8859-1\"\n",
    "\n",
    "# ......\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d100cb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuente el numero de comentarios en cada categoria\n",
    "# cada categoria esta guardada en cada columna, exceptiando el \"id\" y el \"comment text\"\n",
    "\n",
    "#......\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "467ceb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora vamos a graficar estos datos\n",
    "\n",
    "#.....\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9f3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuantos comentarios tienen multilabels?\n",
    "\n",
    "\n",
    "# ....\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d16669",
   "metadata": {},
   "source": [
    "De la grafica anterior se puede ver que una gran cantidad de comentarios no tienen ninguna etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eea3a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcule el porcentaje de los que no estan etiquetados\n",
    "\n",
    "\n",
    "#...\n",
    "\n",
    "# lo que deberia de darles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b2035a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seguimos aprendiendo del contexto\n",
    "\n",
    "# la distribucion del numero de palabras que aparecen en los textos de los comentarios\n",
    "\n",
    "# ....\n",
    "\n",
    "# Como ven, la longitud de la mayoria de textos es de 500 caracteres, exceptuando unos que son hasta de 5000\n",
    "\n",
    "# y luce como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c07dd",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# Miremos si hay comentarios faltantes, mirando dentro de la columna \"comment text\"\n",
    "\n",
    "# ...\n",
    "\n",
    "# Lo que deberia de darles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8d6fc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de comentarios faltantes dentro de la columan \"comment text\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Numero de comentarios faltantes dentro de la columan \"comment text\"')\n",
    "df['comment_text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d30b822a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Echele una mirada  a la primera entrada de datos\n",
    "# compare esta llamada con la que ustedes harian\n",
    "df['comment_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85f11a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cree una funcion que limpie el texto... yo la llame limpie_mi_texto\n",
    "\n",
    "#Utilize re para hacerlo\n",
    "\n",
    "#La funcion recibe un texto y hace los siguiente\n",
    "# Lo convierte a minusculas  (ayuda:  text.lower())\n",
    "# Reemplazar cosas raras como \\'s  \\W \\s+ por \" \" \n",
    "# cambie ciertas cadenas por otras como\n",
    "#  \"\\'ve\"   por \" have \"\n",
    "# \"can't\" por \"can not \"\n",
    "# \"n't\" por \" not \"\n",
    "# \"i'm\" por \" i am \"\n",
    "# \"\\'re\" por \" are \"\n",
    "# \"\\'d\" por \" would \"\n",
    "# \"\\'ll\" por \" will \"\n",
    "# \"\\'scuse\" por \" excuse \"\n",
    "# al final use strip() para borrar de la cadena de caracteres los posible caracteres vacios al principio y al final\n",
    "\n",
    "# la funcion debe regresa el nuevo texto o cadena de caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14814261",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def limpie_mi_texto(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2bff131",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edits made under my username hardcore metallica fan were reverted they were not vandalisms just closure on some gas after i voted at new york dolls fac and please do not remove the template from the talk page since i am retired now 89 205 38 27'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Por ejempo, si hago uso de esta les deberia de dar:\n",
    "df['comment_text'] = df['comment_text'].map(lambda myt : limpie_mi_texto(myt))\n",
    "df['comment_text'][0]\n",
    "\n",
    "# compare el output que sale aqui con el que tenias antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea36d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divida los datos entre entrenamiento y prueba con un 67% para test y 33% para prueba \n",
    "# cuando use la funcion de scikit, echele una mirada al parametro shuffle=True de esa funcion\n",
    "# este mezcla los datos de manera aleatoria antes de dividir los datos\n",
    "\n",
    "# ....\n",
    "\n",
    "# voy a imprimir el \"shape\" del X_train y del X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c75e3604",
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106912,)\n",
      "(52659,)\n"
     ]
    }
   ],
   "source": [
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train, test = train_test_split(df, random_state=42, test_size=0.33, shuffle=True)\n",
    "X_train = train.comment_text\n",
    "X_test = test.comment_text\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a61d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora comenzamos el entrenamiento de varios clasificadores\n",
    "\n",
    "# primero defina un pipeline (recuerde que esto es para hacer varias cosas en scikit)\n",
    "# primero haga uso del TfidfVectorizer(stop_words=stop_words)\n",
    "# Luego defina el clasificador, comenzemoz por uno de los OneVsRestClassifier en particular MultinomialNB\n",
    "# parte de la linea seria:  OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None)\n",
    "\n",
    "# luego que define el pipeline, vamos por las diferentes categorias y entremos el algoritmo y precedimos\n",
    "# aqui imprimo lo que da para categoria (sus numeros puede variar un poco)\n",
    "\n",
    "# serian algo asi como\n",
    "# NB_Pipeline = Pipeline([....])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4656ba92",
   "metadata": {},
   "source": [
    "### SVC Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c044c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haga los mismo pero ahora con el SVC lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12b3a1d",
   "metadata": {},
   "source": [
    "### Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541911ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora hagalo con la regresion logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab0fc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
